# go-evals

A Go library for fast, automated evaluation of Large Language Model (LLM) outputs, heavily inspired by Braintrust's [autoevals](https://github.com/braintrustdata/autoevals). Currently in progress.

## Philosophy

The goal of `go-evals` is to provide a simple, testable, and extensible framework for scoring AI responses in Go. It focuses on lightweight, code-native evaluators to make LLM testing as fast and easy as traditional unit testing.
